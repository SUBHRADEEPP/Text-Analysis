{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa43cd7",
   "metadata": {},
   "source": [
    "## Data Extraction and Text Analysis (Subhradeep Pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a04cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from spacy_syllables import SpacySyllables\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dc9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the input file\n",
    "\n",
    "df_url = pd.read_excel('C:\\\\Users\\\\subhr\\\\Desktop\\\\Internship\\\\Black Coffer\\\\Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01d560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3        40  https://insights.blackcoffer.com/will-machine-...\n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..      ...                                                ...\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110     147  https://insights.blackcoffer.com/the-future-of...\n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112     149  https://insights.blackcoffer.com/business-anal...\n",
       "113     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c27f0",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4495d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web scraping the text data from each and every sites mentioned in the input file using beautifulsoup and requests library\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n",
    "for i,j in enumerate(list(df_url['URL'])):\n",
    "    f=open(\"C:\\\\Users\\\\subhr\\\\Desktop\\\\Internship\\\\Black Coffer\\\\files\\\\\"+str(df_url.iloc[i:i+1,:1]['URL_ID'][i])+\".txt\",\"a\")\n",
    "    page = requests.get(j,headers=headers)\n",
    "    page_soup = BeautifulSoup(page.text,'lxml')\n",
    "    try:\n",
    "        title = page_soup.find('h1',class_='entry-title')\n",
    "        f.write(title.text)\n",
    "        body = page_soup.find('div',class_='td-post-content')\n",
    "        page_content = body.find_all('p')\n",
    "        for p in page_content:\n",
    "            f.write(p.text)\n",
    "        f.close()\n",
    "    except:\n",
    "        f.write('No text could be found.')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de367d5",
   "metadata": {},
   "source": [
    "### Reading stopwords, positive and negative words from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3af7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the stopwords from the files provided\n",
    "\n",
    "stopword_files = ['Auditor','Currencies','DatesandNumbers','Generic','GenericLong','Geographic','Names']\n",
    "stopword_list =[]\n",
    "for file in stopword_files:\n",
    "    f = open('C:\\\\Users\\\\subhr\\\\Desktop\\\\Internship\\\\Black Coffer\\\\StopWords-20221016T122610Z-001\\\\StopWords\\\\StopWords_'+file+'.txt','r')\n",
    "    stopword_list.extend(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8094dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the newline characters from the stopwords using replace function\n",
    "\n",
    "char_to_replace = {'\\n':''}\n",
    "for key,value in char_to_replace.items():\n",
    "    for i in range(len(stopword_list)):\n",
    "        stopword_list[i] = stopword_list[i].lower()\n",
    "        stopword_list[i] = stopword_list[i].replace(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38ce60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the list of positive and negative words provided\n",
    "\n",
    "pos_words=[]\n",
    "neg_words=[]\n",
    "word_files=['positive-words','negative-words']\n",
    "for file in word_files:\n",
    "    fop = open('C:\\\\Users\\\\subhr\\\\Desktop\\\\Internship\\\\Black Coffer\\\\MasterDictionary-20221016T122559Z-001\\\\MasterDictionary\\\\'+file+'.txt','r')\n",
    "    if file == 'positive-words':\n",
    "        pos_words.extend(fop.readlines())\n",
    "    else:\n",
    "        neg_words.extend(fop.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2c934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing newline characters\n",
    "\n",
    "for i in range(len(pos_words)):\n",
    "    pos_words[i]= pos_words[i].replace('\\n','')\n",
    "    \n",
    "for i in range(len(neg_words)):\n",
    "    neg_words[i]= neg_words[i].replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab6531",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314b881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring empty lists\n",
    "\n",
    "positive_score =[]\n",
    "negative_score =[]\n",
    "polarity_score = []\n",
    "subjectivity_score =[]\n",
    "avg_len_sent = []\n",
    "complex_words = []\n",
    "percent_of_cw =[]\n",
    "fog_index = []\n",
    "avg_syllable_count = []\n",
    "pper_count = []\n",
    "word_count = []\n",
    "avg_word_len = []\n",
    "\n",
    "#Opening each and every text file created previously in read mode\n",
    "\n",
    "for i in range(df_url.shape[0]):\n",
    "    file = open('C:\\\\Users\\\\subhr\\\\Desktop\\\\Internship\\\\Black Coffer\\\\files\\\\'+str(df_url.iloc[i:i+1,:1]['URL_ID'][i])+'.txt','r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "#Removing unnecessary punctuations and strings\n",
    "\n",
    "    punc_to_replace = {',':' ','?':' ','(':' ',')':' ','’':' ','“':' ','”':' ','\\xa0':' ','  ':' '}\n",
    "    for key, value in punc_to_replace.items():\n",
    "        lines[0]=lines[0].lower()\n",
    "        lines[0]=lines[0].replace(key,value)\n",
    "\n",
    "#loading spacy english model and adding syllables component to the pipeline after tagger component \n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    nlp.add_pipe(\"syllables\",after='tagger')\n",
    "    doc = nlp(lines[0])\n",
    "\n",
    "#Determining number of words in the text data after removing the punctuations and removing the stopwords provided from the data\n",
    "\n",
    "    word_lemmas = []\n",
    "    for token in doc:\n",
    "        word_lemmas.append(token.lemma_)\n",
    "    num_words = len(word_lemmas)\n",
    "    \n",
    "    for token in word_lemmas:\n",
    "        if token in stopword_list:\n",
    "            word_lemmas.remove(token)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "#Calculating POSITIVE , NEGATIVE, SUBJECTIVITY ,POLARITY SCORE & AVERAGE SENTENCE LENGTH\n",
    "\n",
    "    p=0\n",
    "    n=0\n",
    "    for word in word_lemmas:\n",
    "        if word in pos_words:\n",
    "            p=p+1\n",
    "        elif word in neg_words:\n",
    "            n=n+1\n",
    "        else:\n",
    "            continue\n",
    "    #n = n*(-1)\n",
    "    positive_score.append(p)\n",
    "    negative_score.append(n)\n",
    "    \n",
    "    polarity = (p-n)/((p+n)+0.000001)\n",
    "    polarity = round(polarity,2)\n",
    "    polarity_score.append(polarity)\n",
    "    \n",
    "    subjectivity = (p+n)/(len(word_lemmas)+0.000001)\n",
    "    subjectivity = round(subjectivity,2)\n",
    "    subjectivity_score.append(subjectivity)\n",
    "    \n",
    "    Avg_sent_len = num_words/len(list(doc.sents))\n",
    "    Avg_sent_len = round(Avg_sent_len,2)\n",
    "    avg_len_sent.append(Avg_sent_len)\n",
    "    \n",
    "#Calculating PERCENTAGE OF COMPLEX WORDS & COMPLEX WORD COUNT in the text data\n",
    "    \n",
    "    cw=0\n",
    "    for token in doc:\n",
    "        syllable_count = token._.syllables_count\n",
    "        if syllable_count != None and syllable_count >= 3:\n",
    "            cw = cw +1\n",
    "        else:\n",
    "            continue\n",
    "    complex_words.append(cw)        \n",
    "    \n",
    "    percentage_cw = (cw/num_words)*100\n",
    "    percentage_cw = round(percentage_cw,2)\n",
    "    percent_of_cw.append(percentage_cw)\n",
    "    \n",
    "#Determing FOG INDEX\n",
    "    \n",
    "    fog_i = 0.4*(Avg_sent_len+cw)\n",
    "    fog_i = round(fog_i,2)\n",
    "    fog_index.append(fog_i)\n",
    "\n",
    "#Determning the average syllable count in the text data    \n",
    "    \n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        syllable_c = token._.syllables_count\n",
    "        if syllable_c != None:\n",
    "            count= syllable_c + count\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    avg_syllable_count_word = count/num_words\n",
    "    avg_syllable_count_word = round(avg_syllable_count_word,2)\n",
    "    avg_syllable_count.append(avg_syllable_count_word)\n",
    "\n",
    "#Determing the number of PERSONAL PRONOUNS in the text data    \n",
    "    \n",
    "    prp = 0\n",
    "    for token in doc:\n",
    "        if token.tag_ == 'PRP':\n",
    "            prp = prp +1\n",
    "        else:\n",
    "            continue\n",
    "    pper_count.append(prp)\n",
    "\n",
    "#Calculating the WORD COUNT after removing stopwords using nltk stopwords   \n",
    "    \n",
    "    word_list = []\n",
    "    for token in doc:\n",
    "        word_list.append(token.text)\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word in stopwords.words('english'):\n",
    "            word_list.remove(word)\n",
    "        else:\n",
    "            continue\n",
    "    word_count.append(len(word_list))\n",
    " \n",
    "#Calculating AVERAGE WORD LENTGH in the text data\n",
    "\n",
    "    char_list=[]\n",
    "    for token in doc: \n",
    "        char_list.extend(list(token.text))\n",
    "    char_count = len(char_list)\n",
    "    char_per_word = char_count/num_words\n",
    "    char_per_word = round(char_per_word,2)\n",
    "    avg_word_len.append(char_per_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb8be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "for i in range(df_url.shape[0]):\n",
    "    url.append(df_url.iloc[i:i+1,1:2]['URL'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537fd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_id = range(37,151)\n",
    "columns = ['URL_ID','URL','POSITIVE SCORE','NEGATIVE SCORE','POLARITY SCORE','SUBJECTIVITY SCORE','AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS',\n",
    "           'FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE','COMPLEX WORD COUNT','WORD COUNT','SYLLABLE PER WORD','PERSONAL PRONOUNS','AVERAGE WORD LENGTH']\n",
    "\n",
    "\n",
    "\n",
    "df_new = pd.DataFrame(list(zip(url_id,url,positive_score,negative_score,polarity_score,subjectivity_score,avg_len_sent,\n",
    "                              percent_of_cw,fog_index,avg_len_sent,complex_words,word_count,avg_syllable_count,pper_count,avg_word_len))\n",
    "                      ,columns=columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78512729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVERAGE WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.09</td>\n",
       "      <td>34.13</td>\n",
       "      <td>18.59</td>\n",
       "      <td>153.25</td>\n",
       "      <td>34.13</td>\n",
       "      <td>349</td>\n",
       "      <td>1357</td>\n",
       "      <td>1.64</td>\n",
       "      <td>21</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>24.75</td>\n",
       "      <td>11.59</td>\n",
       "      <td>79.90</td>\n",
       "      <td>24.75</td>\n",
       "      <td>175</td>\n",
       "      <td>1021</td>\n",
       "      <td>1.40</td>\n",
       "      <td>53</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.09</td>\n",
       "      <td>26.48</td>\n",
       "      <td>18.55</td>\n",
       "      <td>142.19</td>\n",
       "      <td>26.48</td>\n",
       "      <td>329</td>\n",
       "      <td>1238</td>\n",
       "      <td>1.62</td>\n",
       "      <td>29</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>62</td>\n",
       "      <td>29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>24.22</td>\n",
       "      <td>13.05</td>\n",
       "      <td>96.89</td>\n",
       "      <td>24.22</td>\n",
       "      <td>218</td>\n",
       "      <td>1141</td>\n",
       "      <td>1.42</td>\n",
       "      <td>53</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.82</td>\n",
       "      <td>14.08</td>\n",
       "      <td>113.53</td>\n",
       "      <td>25.82</td>\n",
       "      <td>258</td>\n",
       "      <td>1270</td>\n",
       "      <td>1.47</td>\n",
       "      <td>56</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>24.48</td>\n",
       "      <td>10.12</td>\n",
       "      <td>30.59</td>\n",
       "      <td>24.48</td>\n",
       "      <td>52</td>\n",
       "      <td>367</td>\n",
       "      <td>1.34</td>\n",
       "      <td>18</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.07</td>\n",
       "      <td>30.33</td>\n",
       "      <td>14.03</td>\n",
       "      <td>78.53</td>\n",
       "      <td>30.33</td>\n",
       "      <td>166</td>\n",
       "      <td>844</td>\n",
       "      <td>1.46</td>\n",
       "      <td>20</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.11</td>\n",
       "      <td>16.88</td>\n",
       "      <td>15.56</td>\n",
       "      <td>15.15</td>\n",
       "      <td>16.88</td>\n",
       "      <td>21</td>\n",
       "      <td>92</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.09</td>\n",
       "      <td>36.50</td>\n",
       "      <td>21.23</td>\n",
       "      <td>27.00</td>\n",
       "      <td>36.50</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17.73</td>\n",
       "      <td>14.36</td>\n",
       "      <td>63.09</td>\n",
       "      <td>17.73</td>\n",
       "      <td>140</td>\n",
       "      <td>676</td>\n",
       "      <td>1.50</td>\n",
       "      <td>18</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                76              35            0.37                0.09   \n",
       "1                74              39            0.31                0.12   \n",
       "2                68              40            0.26                0.09   \n",
       "3                62              29            0.36                0.09   \n",
       "4                62              28            0.38                0.08   \n",
       "..              ...             ...             ...                 ...   \n",
       "109               9              21           -0.40                0.09   \n",
       "110              39              15            0.44                0.07   \n",
       "111               7               3            0.40                0.11   \n",
       "112               8               1            0.78                0.09   \n",
       "113              38              37            0.01                0.12   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                  34.13                        18.59     153.25   \n",
       "1                  24.75                        11.59      79.90   \n",
       "2                  26.48                        18.55     142.19   \n",
       "3                  24.22                        13.05      96.89   \n",
       "4                  25.82                        14.08     113.53   \n",
       "..                   ...                          ...        ...   \n",
       "109                24.48                        10.12      30.59   \n",
       "110                30.33                        14.03      78.53   \n",
       "111                16.88                        15.56      15.15   \n",
       "112                36.50                        21.23      27.00   \n",
       "113                17.73                        14.36      63.09   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                               34.13                 349        1357   \n",
       "1                               24.75                 175        1021   \n",
       "2                               26.48                 329        1238   \n",
       "3                               24.22                 218        1141   \n",
       "4                               25.82                 258        1270   \n",
       "..                                ...                 ...         ...   \n",
       "109                             24.48                  52         367   \n",
       "110                             30.33                 166         844   \n",
       "111                             16.88                  21          92   \n",
       "112                             36.50                  31         100   \n",
       "113                             17.73                 140         676   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVERAGE WORD LENGTH  \n",
       "0                 1.64                 21                 5.43  \n",
       "1                 1.40                 53                 4.57  \n",
       "2                 1.62                 29                 5.21  \n",
       "3                 1.42                 53                 4.64  \n",
       "4                 1.47                 56                 4.75  \n",
       "..                 ...                ...                  ...  \n",
       "109               1.34                 18                 4.52  \n",
       "110               1.46                 20                 4.86  \n",
       "111               1.46                  1                 4.61  \n",
       "112               1.74                  1                 5.58  \n",
       "113               1.50                 18                 4.74  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc32f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('C:\\\\Users\\\\subhr\\\\Desktop\\\\Internship\\\\Black Coffer\\\\Output_SubhradeepPal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42209f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
